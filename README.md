# ComfyUI + ComfyUI Manager â€” CUDA 13.0 Docker Image

[![GitHub Build](https://img.shields.io/github/actions/workflow/status/yannmichaux/comfyui-docker/build.yml?style=for-the-badge&logo=github)](https://github.com/yannmichaux/comfyui-docker/actions)
[![GitHub Release](https://img.shields.io/github/v/release/yannmichaux/comfyui-docker?style=for-the-badge&logo=github)](https://github.com/yannmichaux/comfyui-/releases)
[![Docker Version](https://img.shields.io/docker/v/yannmichaux/comfyui?sort=semver&style=for-the-badge&logo=docker)](https://hub.docker.com/r/yannmichaux/comfyui/tags)
[![License: MIT](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)
[![ComfyUI](https://img.shields.io/badge/Powered%20by-ComfyUI-blueviolet?style=for-the-badge)](https://github.com/comfyanonymous/ComfyUI)

> A ready-to-run **ComfyUI + ComfyUI Manager** Docker image with **CUDA 13.0**, **Python 3.12**, and **PyTorch CU130**, fully GPU-accelerated and optimized for homelabs, servers, and AI workstations.

---

## âœ¨ Overview

This project provides a production-ready Docker image for running **ComfyUI** with **ComfyUI Manager**:

- ğŸ”§ Base image: `nvidia/cuda:13.0.2-runtime-ubuntu24.04`
- ğŸ Python **3.12** in a dedicated virtual environment
- ğŸ”¥ PyTorch (CU130 wheels) for NVIDIA GPU acceleration
- ğŸ§© ComfyUI + ComfyUI Manager preinstalled
- ğŸ“‚ Clean volume structure for `input`, `output`, and `models`
- ğŸŒ Web UI exposed on port **8188**

---

## ğŸ“¦ Docker Hub & Source Code

- **Docker Hub:** [`yannmichaux/comfyui`](https://hub.docker.com/r/yannmichaux/comfyui)
- **GitHub Repo:** [`yannmichaux/comfyui-`](https://github.com/yannmichaux/comfyui-)

---

## ğŸ§± Image Contents

The image includes:

- **OS & Runtime**
  - Ubuntu 24.04
  - CUDA 13.0.2 runtime
- **Language & Libraries**
  - Python 3.12 (`/usr/bin/python3.12`)
  - Virtual environment at `/app/venv`
  - PyTorch + torchvision + torchaudio (CU130 wheels)
- **Applications**
  - ComfyUI (cloned from official repo into `/app/comfyui`)
  - ComfyUI Manager (installed in `custom_nodes`)
- **Ports**
  - Exposes port `8188`

---

## ğŸ“ Container Directory Layout

```text
/app/comfyui
â”œâ”€â”€ input/        # Input images
â”œâ”€â”€ output/       # Generated outputs
â”œâ”€â”€ models/       # Checkpoints, LoRAs, VAEs, upscalers...
â””â”€â”€ custom_nodes/
    â””â”€â”€ ComfyUI-Manager/
```

Mount these directories on the host for persistence.

---

## ğŸš€ Quick Start

### 1. Pull the versioned Docker image

```bash
docker pull yannmichaux/comfyui:latest
```

### 2. Run the container

```bash
docker run -d \
  --gpus all \
  --name comfyui \
  -p 8188:8188 \
  -v /mnt/comfy/input:/app/comfyui/input \
  -v /mnt/comfy/output:/app/comfyui/output \
  -v /mnt/comfy/models:/app/comfyui/models \
  yannmichaux/comfyui:<version>
```

Access ComfyUI:

```
http://localhost:8188
```

---

## ğŸ³ docker-compose Example

```yaml
version: "3.9"

services:
  comfyui:
    image: yannmichaux/comfyui:<version>
    container_name: comfyui
    restart: unless-stopped
    ports:
      - "8188:8188"
    volumes:
      - /mnt/comfy/input:/app/comfyui/input
      - /mnt/comfy/output:/app/comfyui/output
      - /mnt/comfy/models:/app/comfyui/models
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility,video
```

## ğŸ§ª Debugging & Tools

- Follow logs: `docker logs -f comfyui`
- Shell into the container: `docker exec -it comfyui bash`
- GPU checks: `nvidia-smi`

---

## ğŸ¤ Contributing

Contributions are welcome!
Open issues, PRs, or feature requests directly on GitHub.

---

## ğŸ“œ License (MIT)

This project is licensed under the terms of the **MIT License**.
See the [LICENSE](LICENSE) file for details.

---

## ğŸ™Œ Credits

- [ComfyUI](https://github.com/comfyanonymous/ComfyUI)
- [ComfyUI Manager](https://github.com/Comfy-Org/ComfyUI-Manager)
- [NVIDIA CUDA Images](https://hub.docker.com/r/nvidia/cuda)
